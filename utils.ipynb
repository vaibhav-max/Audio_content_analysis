{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retreving the max group size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum group size is: 4204\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('/data/Root_content/Vaani/audio_content_analysis/unique_file_names.csv')\n",
    "\n",
    "# Group by 'File Size with Header (bytes)' and calculate the size of each group\n",
    "group_sizes = df.groupby('File Size with Header (bytes)').size()\n",
    "\n",
    "# Retrieve the maximum group size\n",
    "max_group_size = group_sizes.max()\n",
    "\n",
    "print(f\"The maximum group size is: {max_group_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of each group size (sorted) saved to 'sorted_group_size_occurrences.csv'\n",
      "      Group Size  Occurrences\n",
      "1226        4204            1\n",
      "1232        3393            1\n",
      "1163        3225            1\n",
      "1467        3191            1\n",
      "1494        3186            1\n",
      "...          ...          ...\n",
      "4              5         2772\n",
      "3              4         5314\n",
      "2              3        11052\n",
      "1              2        23728\n",
      "0              1        49149\n",
      "\n",
      "[1519 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('/data/Root_content/Vaani/audio_content_analysis/unique_file_names.csv')\n",
    "\n",
    "# Group by 'File Size with Header (bytes)' and calculate the size of each group\n",
    "group_sizes = df.groupby('File Size with Header (bytes)').size()\n",
    "\n",
    "# Count the occurrences of each group size\n",
    "group_size_occurrences = group_sizes.value_counts()\n",
    "\n",
    "# Convert to a DataFrame for easier viewing\n",
    "group_size_occurrences_df = group_size_occurrences.reset_index(name='Occurrences')\n",
    "group_size_occurrences_df.columns = ['Group Size', 'Occurrences']\n",
    "\n",
    "# Sort the DataFrame by 'Group Size' in ascending order (use ascending=False for descending)\n",
    "sorted_group_size_occurrences_df = group_size_occurrences_df.sort_values(by='Group Size', ascending=False)\n",
    "\n",
    "# Save to a CSV file if needed\n",
    "sorted_group_size_occurrences_df.to_csv('sorted_group_size_occurrences.csv', index=False)\n",
    "\n",
    "print(\"Occurrences of each group size (sorted) saved to 'sorted_group_size_occurrences.csv'\")\n",
    "print(sorted_group_size_occurrences_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reterive all the files with group size 4204 and byte size 87314 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/data/Root_content/Vaani/audio_content_analysis/audio_file_info.csv')\n",
    "\n",
    "# Filter the DataFrame where \"File Size with Header (bytes)\" equals 87314\n",
    "filtered_df = df[df['File Size with Header (bytes)'] == 87314]\n",
    "columns_to_drop = ['Sample Rate', 'Channels', 'Bit Depth', 'Audio Data Size without Header (bytes)', 'Header Size (bytes)']\n",
    "filtered_df = filtered_df.drop(columns=columns_to_drop)\n",
    "\n",
    "filtered_df.to_csv(\"/data/Vaani/Dataset/Group_wise/group_size_87314/group_size_87314.csv\", index=False)\n",
    "# Specify the source base directory where the files are located\n",
    "source_base_dir = '/data/Vaani/Dataset/Audios_all_district_vaani_3' \n",
    "\n",
    "# Specify the destination directory where the files will be copied\n",
    "destination_dir = '/data/Vaani/Dataset/Group_wise/group_size_87314'\n",
    "\n",
    "os.makedirs(destination_dir, exist_ok= True)\n",
    "\n",
    "for filename in filtered_df['File Name']:\n",
    "    folder_name = filename.split('_')[4]\n",
    "    source_folder_path = os.path.join(source_base_dir, folder_name)\n",
    "\n",
    "    source_file_path = os.path.join(source_folder_path, filename)\n",
    "\n",
    "    destination_file_path = os.path.join(destination_dir, filename)\n",
    "\n",
    "    if os.path.exists(source_file_path):\n",
    "        shutil.copy(source_file_path, destination_file_path)\n",
    "    # else :\n",
    "    #     print(\"file_not_found\", source_file_path)\n",
    "\n",
    "print(\"Files have been copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make the csv file which contains all the file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_filenames.csv' has been created with 3700 filenames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Specify the directory containing .wav files\n",
    "directory = '/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/files'\n",
    "\n",
    "# Create a list to hold the filenames\n",
    "filenames = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        filenames.append(filename)\n",
    "\n",
    "# Specify the CSV file to save the filenames\n",
    "csv_filename = '/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_filenames.csv'\n",
    "\n",
    "# Write the filenames to the CSV file\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Filename\"])  # Writing the header\n",
    "    for name in filenames:\n",
    "        writer.writerow([name])\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' has been created with {len(filenames)} filenames.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retreving the embedding of the audio files using wav2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "# Load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Folder containing audio files\n",
    "folder_path = \"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/files\"\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = \"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_filenames.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to get transcription\n",
    "def get_transcription(file_name):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        input_values = processor(audio, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0]\n",
    "        return transcription\n",
    "    return None\n",
    "\n",
    "# Add a new column for transcriptions\n",
    "df['Transcription'] = df['Filename'].apply(get_transcription)\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_transcription.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'BLOACA PSYCHE CUDIN DEE'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "# Load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Folder containing audio files\n",
    "file_path = \"/data/Vaani/Dataset/Group_wise/group_size_87314/IISc_VaaniProject_M_UP_Etah_Nira60087_1313120000_APVCYR_74609_12416_15104.wav\"\n",
    "\n",
    "# Function to get transcription\n",
    "def get_transcription(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        input_values = processor(audio, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0]\n",
    "        return transcription\n",
    "    return None\n",
    "\n",
    "get_transcription(file_path)\n",
    "# \"ELEGAP THE FLEW BUT THE BARRAN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "# Load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Folder containing audio files\n",
    "folder_path = \"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/files\"\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = \"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_filenames.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to get transcription\n",
    "def get_transcription(file_name):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        input_values = processor(audio, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "        input_values = input_values.to(device)\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0]\n",
    "        return transcription\n",
    "    return None\n",
    "\n",
    "# Add a new column for transcriptions\n",
    "df['Transcription'] = df['Filename'].apply(get_transcription)\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_transcription.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.000000] ITTON YO TO EXPS PA LONOCE\n",
      "* [SIM=0.946985] LOP ACTEHE OR\n",
      "* [SIM=1.028532] ALL THE EXAINBARD ADDE YE\n",
      "* [SIM=1.030308] SO YO NO AT EGOUL LOOK AT FOR IKE GOIN TO PLAS AT A THE LOG\n",
      "* [SIM=1.039297] E GO WEN NI TOE TO THE LAY PANGE PA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.documents import Document\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file containing transcriptions\n",
    "csv_file_path = \"/data/Vaani/Dataset/Group_wise/group_size_87314/group_size_87314_transcription.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Initialize the Sentence Transformer model\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Generate embeddings for each transcription\n",
    "transcriptions = df['Transcription'].tolist()\n",
    "embedding_vectors = model.encode(transcriptions)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = embedding_vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_vectors)\n",
    "\n",
    "# Create a document store and index-to-docstore ID mapping\n",
    "docstore = InMemoryDocstore({str(idx): Document(page_content=transcription) for idx, transcription in enumerate(transcriptions)})\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(transcriptions))}\n",
    "\n",
    "# Create FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=lambda x: model.encode(x),\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# Perform a similarity search with scores\n",
    "query = \"ITTON YO TO EXPS PA LONOCE\"\n",
    "results = vector_store.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# Output results with similarity scores\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:.6f}] {res.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=1.000] ITTON YO TO EXPS PA LONOCE\n",
      "* [SIM=0.527] LOP ACTEHE OR\n",
      "* [SIM=0.486] ALL THE EXAINBARD ADDE YE\n",
      "* [SIM=0.485] SO YO NO AT EGOUL LOOK AT FOR IKE GOIN TO PLAS AT A THE LOG\n",
      "* [SIM=0.480] E GO WEN NI TOE TO THE LAY PANGE PA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.documents import Document\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file containing transcriptions\n",
    "csv_file_path = \"/data/Vaani/Dataset/Group_wise/group_size_87314/group_size_87314_transcription.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Initialize the Sentence Transformer model\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Generate embeddings for each transcription\n",
    "transcriptions = df['Transcription'].tolist()\n",
    "embedding_vectors = model.encode(transcriptions)\n",
    "\n",
    "# Normalize embeddings to use cosine similarity\n",
    "embedding_vectors = embedding_vectors / np.linalg.norm(embedding_vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Initialize FAISS index for inner product (cosine similarity)\n",
    "dimension = embedding_vectors.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Use IndexFlatIP for cosine similarity\n",
    "index.add(embedding_vectors)\n",
    "\n",
    "# Create a document store and index-to-docstore ID mapping\n",
    "docstore = InMemoryDocstore({str(idx): Document(page_content=transcription) for idx, transcription in enumerate(transcriptions)})\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(transcriptions))}\n",
    "\n",
    "# Create FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=lambda x: model.encode(x),\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# Perform a similarity search with scores\n",
    "query = \"ITTON YO TO EXPS PA LONOCE\"\n",
    "results = vector_store.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# Output results with similarity scores\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:.3f}] {res.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying FAISS on all the files in the group of size 87314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/pyannote/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.documents import Document\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file containing transcriptions\n",
    "csv_file_path = \"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/audio_transcription.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "# Initialize the Sentence Transformer model\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Generate embeddings for each transcription\n",
    "transcriptions = df['Transcription'].tolist()\n",
    "filenames = df['Filename'].tolist()\n",
    "embedding_vectors = model.encode(transcriptions)\n",
    "\n",
    "# Normalize embeddings to use cosine similarity\n",
    "embedding_vectors = embedding_vectors / np.linalg.norm(embedding_vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Initialize FAISS index for inner product (cosine similarity)\n",
    "dimension = embedding_vectors.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Use IndexFlatIP for cosine similarity\n",
    "index.add(embedding_vectors)\n",
    "\n",
    "# Create a dictionary with filenames as keys and transcriptions as values\n",
    "transcription_dict = {filename: transcription for filename, transcription in zip(filenames, transcriptions)}\n",
    "\n",
    "# Create a reverse dictionary to map transcriptions back to filenames\n",
    "reverse_transcription_dict = {transcription: filename for filename, transcription in transcription_dict.items()}\n",
    "\n",
    "# Create a document store with filenames as keys\n",
    "docstore = InMemoryDocstore({filename: Document(page_content=transcription) for filename, transcription in transcription_dict.items()})\n",
    "index_to_docstore_id = {i: filename for i, filename in enumerate(filenames)}\n",
    "\n",
    "# Create FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=lambda x: model.encode(x),\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# Prepare a list to store results\n",
    "results_list = []\n",
    "\n",
    "# Perform a similarity search for each transcription\n",
    "for filename, query in transcription_dict.items():\n",
    "    try:\n",
    "        search_results = vector_store.similarity_search_with_score(query, k=2)  # k=2 to get top 2 similar transcriptions\n",
    "        \n",
    "        for res, score in search_results:\n",
    "            # Extract the transcription from the result\n",
    "            result_transcription = res.page_content\n",
    "            \n",
    "            # Use the reverse dictionary to get the filename for the result transcription\n",
    "            result_filename = reverse_transcription_dict.get(result_transcription, None)\n",
    "            \n",
    "            if result_filename is None:\n",
    "                print(f\"Result transcription not found in reverse dictionary: {result_transcription}\")\n",
    "                continue\n",
    "            \n",
    "            if result_filename == filename:  # Skip the result of the query itself\n",
    "                continue\n",
    "            \n",
    "            filename_link = \"https://vaani.iisc.ac.in/Audios/\" + filename.split('_')[4] + \"/\" + filename\n",
    "            result_filename_link = 'https://vaani.iisc.ac.in/Audios/' + result_filename.split('_')[4] + '/' + result_filename\n",
    "            \n",
    "            result_row = {\n",
    "                \"Filename_1\": filename,\n",
    "                \"Filename_2\": result_filename,\n",
    "                \"Similarity_score\": round(score,3)\n",
    "            }\n",
    "            results_list.append(result_row)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {filename} due to error: {e}\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/similarity_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove duplicates from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved to /data/Root_content/Vaani/audio_content_analysis/audio_matched_files/similarity_results_unique_pair.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/similarity_results.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a set to track unique pairs\n",
    "unique_pairs = set()\n",
    "\n",
    "# Function to create an unordered pair as a tuple\n",
    "def make_pair(row):\n",
    "    return tuple(sorted([row['Filename_1'], row['Filename_2']]))\n",
    "\n",
    "# Identify and remove duplicate pairs\n",
    "filtered_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    pair = make_pair(row)\n",
    "    if pair not in unique_pairs:\n",
    "        unique_pairs.add(pair)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Create a new DataFrame with the filtered rows\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "# Save the cleaned data back to a new CSV file\n",
    "output_path = '/data/Root_content/Vaani/audio_content_analysis/audio_matched_files/similarity_results_unique_pair.csv'\n",
    "filtered_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned CSV saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding the number of common files from refernce and 60 lakhs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 File Name   Duration  \\\n",
      "0        https://vaani.iisc.ac.in/Audios/Sukma/IISc_Vaa...   4.100000   \n",
      "1        https://vaani.iisc.ac.in/Audios/Sukma/IISc_Vaa...   5.560000   \n",
      "2        https://vaani.iisc.ac.in/Audios/Sukma/IISc_Vaa...   9.192000   \n",
      "3        https://vaani.iisc.ac.in/Audios/Sukma/IISc_Vaa...   8.775000   \n",
      "4        https://vaani.iisc.ac.in/Audios/Sukma/IISc_Vaa...  12.440000   \n",
      "...                                                    ...        ...   \n",
      "5908590  https://vaani.iisc.ac.in/Audios/North24P/IISc_...   7.093312   \n",
      "5908591  https://vaani.iisc.ac.in/Audios/North24P/IISc_...   5.418687   \n",
      "5908592  https://vaani.iisc.ac.in/Audios/North24P/IISc_...   2.069313   \n",
      "5908593  https://vaani.iisc.ac.in/Audios/North24P/IISc_...   3.914687   \n",
      "5908594  https://vaani.iisc.ac.in/Audios/North24P/IISc_...   5.589313   \n",
      "\n",
      "         Byte Size                                      Transcription  \n",
      "0           132498  O E DEY WE TIO SO POR OMO A HAIR YOU SA ON A B...  \n",
      "1           179218  CUSH LOK WHO SEROU PAT CARE HO KET DE FRAHAR A...  \n",
      "2           295442  AONYCLOLITE ARCACHE DO MA DOLTDICTE BATIQI TO ...  \n",
      "3           282098  IS IMEN ME A MAN A CMARGET GO THE CADARA JOKI ...  \n",
      "4           399378  CANADA ETICHUBJIR IGITA ALONRA DIC DEACI THATR...  \n",
      "...            ...                                                ...  \n",
      "5908590     228284  IGI BORDON AGUED ON O VISTAL DI CANELASTE ONI ...  \n",
      "5908591     174696  O DE DI TOAT SHE TO CHECT OF WORKO THAT  MONE ...  \n",
      "5908592      67516                                  DIDELIGTI DE IVON  \n",
      "5908593     126568  DE MARKET WITET TO A CHARMAN MARKET DOL LOTTER...  \n",
      "5908594     180156                           DRONA GARDEN BORUMILI LI  \n",
      "\n",
      "[5908595 rows x 4 columns]\n",
      "Total number of common files: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSV files into dataframes\n",
    "df1 = pd.read_csv('/data/Root_content/Vaani/audio_content_analysis/audio_analysis_all_group/audio_transcription_without_batch/audio_transcription_csv/audio_link_trancription_without_batching_all_removed_duplicates.csv')\n",
    "df2 = pd.read_csv('/data/Root_content/Vaani/audio_content_analysis/audio_matched_files_tsv/audio_transcription.csv')\n",
    "\n",
    "\n",
    "print(df1)\n",
    "\n",
    "def clean_filename(filename):\n",
    "    return '_'.join(filename.split('/')[-1].split('_')[3:])\n",
    "\n",
    "# clean_filename(\"/data/Vaani/Dataset/Audios_all_district_vaani_1/Sukma/IISc_VaaniProject_S_Chhattisgarh_Sukma_114191_12208498_APCTFLM_226630_7402_11502.wav\")\n",
    "\n",
    "# Apply the cleaning function to the filenames in df2\n",
    "df1['cleaned_filename'] = df1['File Name'].apply(clean_filename)\n",
    "\n",
    "# Now merge based on the cleaned filenames from df2 and filenames from df1\n",
    "common_files = pd.merge(df2[['Filename']], df1[['cleaned_filename']], left_on='Filename', right_on='cleaned_filename')\n",
    "\n",
    "# Count how many files are common\n",
    "common_count = common_files.shape[0]\n",
    "\n",
    "print(f'Total number of common files: {common_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
